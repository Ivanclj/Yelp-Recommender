{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k,auc_score,reciprocal_rank\n",
    "import scipy\n",
    "import time\n",
    "import math\n",
    "from lightfm.data import Dataset\n",
    "import sys\n",
    "sys.path.append(\"/Users/noraxu/MSiA-Google/MSiABlog/\")\n",
    "import Rec_fx as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data_users = pd.read_csv('/Users/noraxu/MSiA-Google/MSiABlog/users_toronto.csv',index_col=0)\n",
    "data_business = pd.read_csv('/Users/noraxu/MSiA-Google/MSiABlog/business_Nora.csv',index_col=0)\n",
    "#data_review = pd.read_csv('/Users/noraxu/MSiA-Google/MSiABlog/reviews_toronto.csv',index_col=0)\n",
    "data_review = pd.read_csv('/Users/noraxu/MSiA-Google/MSiABlog/reviews_cleaned.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_review.cool = pd.Series([math.log(x+1) for x in data_review.cool])\n",
    "data_review.useful = pd.Series([math.log(x+1) for x in data_review.useful])\n",
    "data_review.funny = pd.Series([math.log(x+1) for x in data_review.funny])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coffee &amp; Tea</th>\n",
       "      <th>Nightlife</th>\n",
       "      <th>Bars</th>\n",
       "      <th>Specialty Food</th>\n",
       "      <th>Sandwiches</th>\n",
       "      <th>Breakfast &amp; Brunch</th>\n",
       "      <th>Canadian (New)</th>\n",
       "      <th>Cafes</th>\n",
       "      <th>Chinese</th>\n",
       "      <th>Italian</th>\n",
       "      <th>...</th>\n",
       "      <th>Halal</th>\n",
       "      <th>Gluten-Free</th>\n",
       "      <th>Food Delivery Services</th>\n",
       "      <th>Wine Bars</th>\n",
       "      <th>Delis</th>\n",
       "      <th>Health Markets</th>\n",
       "      <th>Tea Rooms</th>\n",
       "      <th>Sports Bars</th>\n",
       "      <th>Gastropubs</th>\n",
       "      <th>Tapas/Small Plates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "      <td>10093.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.150003</td>\n",
       "      <td>0.634750</td>\n",
       "      <td>0.629464</td>\n",
       "      <td>0.833237</td>\n",
       "      <td>0.936205</td>\n",
       "      <td>0.858503</td>\n",
       "      <td>0.806546</td>\n",
       "      <td>0.860503</td>\n",
       "      <td>1.292694</td>\n",
       "      <td>1.164600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870183</td>\n",
       "      <td>0.739202</td>\n",
       "      <td>0.847934</td>\n",
       "      <td>0.563895</td>\n",
       "      <td>0.889617</td>\n",
       "      <td>0.755071</td>\n",
       "      <td>0.970510</td>\n",
       "      <td>0.572519</td>\n",
       "      <td>0.827071</td>\n",
       "      <td>0.736900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.266034</td>\n",
       "      <td>1.849299</td>\n",
       "      <td>1.871181</td>\n",
       "      <td>3.056503</td>\n",
       "      <td>3.734560</td>\n",
       "      <td>3.510237</td>\n",
       "      <td>3.297011</td>\n",
       "      <td>3.564660</td>\n",
       "      <td>5.291207</td>\n",
       "      <td>4.951080</td>\n",
       "      <td>...</td>\n",
       "      <td>7.464651</td>\n",
       "      <td>6.466833</td>\n",
       "      <td>7.853991</td>\n",
       "      <td>5.095669</td>\n",
       "      <td>8.485234</td>\n",
       "      <td>7.102677</td>\n",
       "      <td>9.151189</td>\n",
       "      <td>5.279457</td>\n",
       "      <td>8.648734</td>\n",
       "      <td>7.930511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.256579</td>\n",
       "      <td>16.783993</td>\n",
       "      <td>11.702970</td>\n",
       "      <td>24.348315</td>\n",
       "      <td>27.663830</td>\n",
       "      <td>27.861429</td>\n",
       "      <td>28.102305</td>\n",
       "      <td>28.680882</td>\n",
       "      <td>29.912577</td>\n",
       "      <td>30.908082</td>\n",
       "      <td>...</td>\n",
       "      <td>130.020000</td>\n",
       "      <td>90.923077</td>\n",
       "      <td>140.309353</td>\n",
       "      <td>60.009231</td>\n",
       "      <td>152.367188</td>\n",
       "      <td>102.377953</td>\n",
       "      <td>154.785714</td>\n",
       "      <td>78.641129</td>\n",
       "      <td>157.282258</td>\n",
       "      <td>189.349515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coffee & Tea     Nightlife          Bars  Specialty Food    Sandwiches  \\\n",
       "count  10093.000000  10093.000000  10093.000000    10093.000000  10093.000000   \n",
       "mean       1.150003      0.634750      0.629464        0.833237      0.936205   \n",
       "std        3.266034      1.849299      1.871181        3.056503      3.734560   \n",
       "min        0.000000      0.000000      0.000000        0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000        0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000        0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000        0.000000      0.000000   \n",
       "max       14.256579     16.783993     11.702970       24.348315     27.663830   \n",
       "\n",
       "       Breakfast & Brunch  Canadian (New)         Cafes       Chinese  \\\n",
       "count        10093.000000    10093.000000  10093.000000  10093.000000   \n",
       "mean             0.858503        0.806546      0.860503      1.292694   \n",
       "std              3.510237        3.297011      3.564660      5.291207   \n",
       "min              0.000000        0.000000      0.000000      0.000000   \n",
       "25%              0.000000        0.000000      0.000000      0.000000   \n",
       "50%              0.000000        0.000000      0.000000      0.000000   \n",
       "75%              0.000000        0.000000      0.000000      0.000000   \n",
       "max             27.861429       28.102305     28.680882     29.912577   \n",
       "\n",
       "            Italian         ...                 Halal   Gluten-Free  \\\n",
       "count  10093.000000         ...          10093.000000  10093.000000   \n",
       "mean       1.164600         ...              0.870183      0.739202   \n",
       "std        4.951080         ...              7.464651      6.466833   \n",
       "min        0.000000         ...              0.000000      0.000000   \n",
       "25%        0.000000         ...              0.000000      0.000000   \n",
       "50%        0.000000         ...              0.000000      0.000000   \n",
       "75%        0.000000         ...              0.000000      0.000000   \n",
       "max       30.908082         ...            130.020000     90.923077   \n",
       "\n",
       "       Food Delivery Services     Wine Bars         Delis  Health Markets  \\\n",
       "count            10093.000000  10093.000000  10093.000000    10093.000000   \n",
       "mean                 0.847934      0.563895      0.889617        0.755071   \n",
       "std                  7.853991      5.095669      8.485234        7.102677   \n",
       "min                  0.000000      0.000000      0.000000        0.000000   \n",
       "25%                  0.000000      0.000000      0.000000        0.000000   \n",
       "50%                  0.000000      0.000000      0.000000        0.000000   \n",
       "75%                  0.000000      0.000000      0.000000        0.000000   \n",
       "max                140.309353     60.009231    152.367188      102.377953   \n",
       "\n",
       "          Tea Rooms   Sports Bars    Gastropubs  Tapas/Small Plates  \n",
       "count  10093.000000  10093.000000  10093.000000        10093.000000  \n",
       "mean       0.970510      0.572519      0.827071            0.736900  \n",
       "std        9.151189      5.279457      8.648734            7.930511  \n",
       "min        0.000000      0.000000      0.000000            0.000000  \n",
       "25%        0.000000      0.000000      0.000000            0.000000  \n",
       "50%        0.000000      0.000000      0.000000            0.000000  \n",
       "75%        0.000000      0.000000      0.000000            0.000000  \n",
       "max      154.785714     78.641129    157.282258          189.349515  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_business.iloc[:,24:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num users: 92381, num_items 10093.\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "dataset = Dataset()\n",
    "dataset.fit(data_review.user_id,data_review.business_id)\n",
    "type(dataset)\n",
    "num_users, num_items = dataset.interactions_shape()\n",
    "print('Num users: {}, num_items {}.'.format(num_users, num_items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit item and user features. \n",
    "dataset.fit_partial(items=data_business.business_id,\n",
    "                    item_features=['stars'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "# #                     item_features=data_business.longitude)\n",
    "# # dataset.fit_partial(items=data_business.business_id,\n",
    "# #                     item_features=data_business.latitude)\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business.review_count)\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Coffee & Tea'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Nightlife'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Bars'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Specialty Food'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Sandwiches'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Breakfast & Brunch'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Canadian (New)'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Cafes'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Chinese'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Italian'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Bakeries'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Pizza'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Japanese'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Desserts'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Fast Food'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Burgers'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['American (Traditional)'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Sushi Bars'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Event Planning & Services'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Grocery'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Nightlife'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Indian'])\n",
    "# dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business['Middle Eastern'])\n",
    "\n",
    "# 'Mediterranean', 'Asian Fusion',\n",
    " #      'Ice Cream & Frozen Yogurt', 'Thai', 'Mexican', 'Pubs'\n",
    "# # fit tags\n",
    "# start_idx = 24\n",
    "# for i in range(start_idx,len(data_business.columns)):\n",
    "#     dataset.fit_partial(items=data_business.business_id,\n",
    "#                     item_features=data_business[data_business.columns[i]])\n",
    "   \n",
    "    \n",
    "tar_cols = [x for x in data_business.columns[24:]]\n",
    "\n",
    "dataset.fit_partial(items = data_business.business_id,\n",
    "                   item_features = tar_cols)                               \n",
    "                                                                                                \n",
    "                                                \n",
    "# dataset.fit_partial(users=data_users.user_id,\n",
    "#                     user_features=data_users.review_count)\n",
    "# dataset.fit_partial(users=data_users.user_id,\n",
    "#                     user_features=data_users.is_elite)\n",
    "# dataset.fit_partial(users=data_users.user_id,\n",
    "#                     user_features=data_users.useful)\n",
    "# dataset.fit_partial(users=data_users.user_id,\n",
    "#                     user_features=data_users.year)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cols = [x for x in data_users.columns[[18,19,22,23]]]\n",
    "dataset.fit_partial(users=data_users.user_id,\n",
    "                    user_features = user_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_cols = ['stars','longitude','latitude','review_count']+[x for x in data_business.columns[24:]]\n",
    "# target_cols = ['stars','review_count','Coffee & Tea', 'Nightlife',\n",
    "#        'Bars', 'Specialty Food', 'Sandwiches', 'Breakfast & Brunch',\n",
    "#        'Canadian (New)', 'Cafes', 'Chinese', 'Italian', 'Bakeries', 'Pizza',\n",
    "#        'Japanese', 'Desserts', 'Fast Food', 'Burgers',\n",
    "#        'American (Traditional)', 'Sushi Bars', 'Event Planning & Services',\n",
    "#        'Grocery', 'Indian', 'Middle Eastern', 'Mediterranean', 'Asian Fusion',\n",
    "#        'Ice Cream & Frozen Yogurt', 'Thai', 'Mexican', 'Pubs']#,'review_count']+[x for x in data_business.columns[24:]]\n",
    "\n",
    "# print(target_cols)\n",
    "\n",
    "# item_features = dataset.build_item_features([(x['business_id'], \n",
    "#                                               [y for y in x[target_cols]])\n",
    "#                                               for index,x in data_business.iterrows()],normalize = True)\n",
    "# user_features = dataset.build_user_features([(x['user_id'],\n",
    "#                                              [x['review_count'],x['is_elite'],x['useful'],x['year']])\n",
    "#                                            for index, x in data_users.iterrows()], normalize =False)\n",
    "\n",
    "# print(repr(item_features))\n",
    "# print(item_features.shape)\n",
    "\n",
    "# print(repr(user_features))\n",
    "# print(user_features.shape)\n",
    "\n",
    "#build interaction\n",
    "(interactions, weights) = dataset.build_interactions([(x['user_id'],\n",
    "                                                       x['business_id'],\n",
    "                                                       x['stars']) for index,x in data_review.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#build interaction\n",
    "def build_dict(df,tar_cols):\n",
    "    rst = {}\n",
    "    for col in tar_cols:\n",
    "        if(df[col]>1):\n",
    "            rst[col]=math.log(df[col])\n",
    "        else:\n",
    "            rst[col] = df[col]\n",
    "    return rst\n",
    "\n",
    "item_features = dataset.build_item_features(((x['business_id'], \n",
    "                                              {'stars':x['stars'],**build_dict(x,tar_cols)})\n",
    "                                              for index,x in data_business.iterrows()))\n",
    "\n",
    "user_features = dataset.build_user_features([(x['user_id'],\n",
    "                                             {'review_count':x['review_count'],'is_elite':x['is_elite'],\n",
    "                                              'useful':x['useful'],'year':x['year']})\n",
    "                                           for index, x in data_users.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 92381 users and 10093 items, with 82127 interactions in the test and 328507 interactions in the training set.\n"
     ]
    }
   ],
   "source": [
    "#train-test split\n",
    "\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "train,test=random_train_test_split(interactions,test_percentage=0.2,random_state=np.random.RandomState(123))\n",
    "\n",
    "print('The dataset has %s users and %s items, '\n",
    "      'with %s interactions in the test and %s interactions in the training set.'\n",
    "      % (train.shape[0], train.shape[1], test.getnnz(), train.getnnz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.1 s, sys: 138 ms, total: 23.2 s\n",
      "Wall time: 23.5 s\n",
      "Collaborative filtering train AUC: 0.82998383\n",
      "Collaborative filtering test AUC: 0.8219651\n"
     ]
    }
   ],
   "source": [
    "#model construction\n",
    "\n",
    "from lightfm import LightFM\n",
    "\n",
    "# Set the number of threads; you can increase this\n",
    "# if you have more physical cores available.\n",
    "NUM_THREADS = 2\n",
    "NUM_COMPONENTS = 90    \n",
    "NUM_EPOCHS = 30\n",
    "ITEM_ALPHA = 1e-6\n",
    "learning_rate=0.03\n",
    "\n",
    "# Let's fit a WARP model: these generally have the best performance.\n",
    "model = LightFM(loss='logistic',random_state=123,\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "               no_components=NUM_COMPONENTS,\n",
    "               learning_rate=learning_rate)\n",
    "\n",
    "# Run 3 epochs and time it.\n",
    "%time model = model.fit(train,epochs=NUM_EPOCHS,num_threads=NUM_THREADS)\n",
    "\n",
    "\n",
    "# Import the evaluation routines\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(model, train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)#logistic: 0.83, warp: 0.997\n",
    "\n",
    "# We pass in the train interactions to exclude them from predictions.\n",
    "# This is to simulate a recommender system where we do not\n",
    "# re-recommend things the user has already interacted with in the train\n",
    "# set.\n",
    "\n",
    "\n",
    "test_auc = auc_score(model, test,num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering test AUC: %s' % test_auc)#test: 0.828, warp:0.825\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of threads; you can increase this\n",
    "# if you have more physical cores available.\n",
    "NUM_THREADS = 2\n",
    "NUM_COMPONENTS = 90    \n",
    "NUM_EPOCHS = 30\n",
    "ITEM_ALPHA = 1e-6\n",
    "learning_rate=0.03\n",
    "\n",
    "# Let's fit a WARP model: these generally have the best performance.\n",
    "model = LightFM(loss='warp',random_state=123,\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "               no_components=NUM_COMPONENTS,\n",
    "               learning_rate=learning_rate)\n",
    "\n",
    "# Run 3 epochs and time it.\n",
    "%time model = model.fit(train,epochs=NUM_EPOCHS,num_threads=NUM_THREADS)\n",
    "\n",
    "\n",
    "# Import the evaluation routines\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(model, train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)#logistic: 0.83, warp: 0.997\n",
    "\n",
    "# We pass in the train interactions to exclude them from predictions.\n",
    "# This is to simulate a recommender system where we do not\n",
    "# re-recommend things the user has already interacted with in the train\n",
    "# set.\n",
    "\n",
    "\n",
    "test_auc = auc_score(model, test,num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering test AUC: %s' % test_auc)#test: 0.828, warp:0.825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now include item features\n",
    "model.ii = LightFM(loss='logistic',random_state=123,\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "               no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Run 3 epochs and time it.\n",
    "%time model.ii = model.ii.fit(train,item_features=item_features,epochs=NUM_EPOCHS,num_threads=NUM_THREADS)\n",
    "\n",
    "\n",
    "# Import the evaluation routines\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(model.ii, train,item_features=item_features, num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid train AUC: %s' % train_auc)#0.9545\n",
    "\n",
    "# We pass in the train interactions to exclude them from predictions.\n",
    "# This is to simulate a recommender system where we do not\n",
    "# re-recommend things the user has already interacted with in the train\n",
    "# set.\n",
    "\n",
    "\n",
    "test_auc = auc_score(model.ii, test,item_features=item_features,num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid test AUC: %s' % test_auc)#0.81,#0.803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 16s, sys: 1.49 s, total: 9min 18s\n",
      "Wall time: 9min 22s\n",
      " Hybrid train AUC: 0.99385494\n",
      " Hybrid test AUC: 0.7357032\n"
     ]
    }
   ],
   "source": [
    "#Now include item features\n",
    "model.ii = LightFM(loss='warp',random_state=123,\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "               no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Run 3 epochs and time it.\n",
    "%time model.ii = model.ii.fit(train,item_features=item_features,epochs=NUM_EPOCHS,num_threads=NUM_THREADS)\n",
    "\n",
    "\n",
    "# Import the evaluation routines\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(model.ii, train,item_features=item_features, num_threads=NUM_THREADS).mean()\n",
    "print(' Hybrid train AUC: %s' % train_auc)#0.9545\n",
    "\n",
    "# We pass in the train interactions to exclude them from predictions.\n",
    "# This is to simulate a recommender system where we do not\n",
    "# re-recommend things the user has already interacted with in the train\n",
    "# set.\n",
    "\n",
    "\n",
    "test_auc = auc_score(model.ii, test,item_features=item_features,num_threads=NUM_THREADS).mean()\n",
    "print(' Hybrid test AUC: %s' % test_auc)#0.81,#0.803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Combine user_feature\n",
    "model.iii = LightFM(loss='logistic',\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "               no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Run 3 epochs and time it.\n",
    "%time model.iii = model.iii.fit(train,user_features=user_features,item_features=item_features,epochs=NUM_EPOCHS,num_threads=NUM_THREADS)\n",
    "\n",
    "\n",
    "# Import the evaluation routines\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(model.iii, train,user_features=user_features,item_features=item_features, num_threads=NUM_THREADS).mean()\n",
    "print(' Hybrid train AUC: %s' % train_auc)#0.945\n",
    "\n",
    "# We pass in the train interactions to exclude them from predictions.\n",
    "# This is to simulate a recommender system where we do not\n",
    "# re-recommend things the user has already interacted with in the train\n",
    "# set.\n",
    "\n",
    "\n",
    "test_auc = auc_score(model.iii, test,user_features=user_features,item_features=item_features,num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid test AUC: %s' % test_auc)#0.789,#0.784\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 25s, sys: 955 ms, total: 11min 26s\n",
      "Wall time: 11min 28s\n",
      "Hybrid train AUC: 0.83197063\n",
      "Hybrid test AUC: 0.8234972\n"
     ]
    }
   ],
   "source": [
    "#Combine user_feature\n",
    "model.iii = LightFM(loss='warp',\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "               no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Run 3 epochs and time it.\n",
    "%time model.iii = model.iii.fit(train,user_features=user_features,item_features=item_features,epochs=NUM_EPOCHS,num_threads=NUM_THREADS)\n",
    "\n",
    "\n",
    "# Import the evaluation routines\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(model.iii, train,user_features=user_features,item_features=item_features, num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid train AUC: %s' % train_auc)#0.945\n",
    "\n",
    "# We pass in the train interactions to exclude them from predictions.\n",
    "# This is to simulate a recommender system where we do not\n",
    "# re-recommend things the user has already interacted with in the train\n",
    "# set.\n",
    "\n",
    "\n",
    "test_auc = auc_score(model.iii, test,user_features=user_features,item_features=item_features,num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid test AUC: %s' % test_auc)#0.789,#0.784, #0.839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
